{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "\n",
    "    def __init__(self, sizes, func_model):\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        self.activate_func = func_model[\"activate_func\"]\n",
    "        self.activate_func_prime = func_model[\"activate_func_prime\"]\n",
    "        self.cost_func = func_model[\"cost_func\"]\n",
    "        self.cost_derivative = func_model[\"cost_derivative\"]\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = self.activate_func(np.dot(w, a) + b)\n",
    "        return a\n",
    "\n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta, \n",
    "            test_data=None,\n",
    "            plot=False\n",
    "            lmbda=0.0):\n",
    "        training_data = list(training_data)\n",
    "        n = len(training_data)\n",
    "        epoch_eval=[]\n",
    "        \n",
    "        if test_data:\n",
    "            test_data = list(test_data)\n",
    "            n_test = len(test_data)\n",
    "        \n",
    "        for j in range(epochs):\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [\n",
    "                training_data[k:k + mini_batch_size]\n",
    "                for k in range(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta, lmbda, len(training_data))\n",
    "            if test_data:\n",
    "                error=self.evaluate(test_data)\n",
    "\n",
    "                if plot:\n",
    "                    epoch_eval.append(error)\n",
    "                print(\"Epoch {} Cost: {}\".format(\n",
    "                    j, error))\n",
    "            else:\n",
    "                print(\"Epoch {} complete\".format(j))\n",
    "        if plot:\n",
    "            plt.plot(epoch_eval)\n",
    "            plt.show()\n",
    "\n",
    "    def evaluate(self,test_data):\n",
    "        def std(a,y):\n",
    "            return np.sqrt((a-y)**2)\n",
    "        return np.array([std(self.feedforward(item[0]),item[1]) for item in test_data]).mean()\n",
    "\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta, lmbda, n):\n",
    "\n",
    "#         nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "#         nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "#         for x, y in mini_batch:\n",
    "#             delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "#             nabla_b = [nb + dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "#             nabla_w = [nw + dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "#         self.weights = [w - (eta / len(mini_batch)) * nw\n",
    "#                         for w, nw in zip(self.weights, nabla_w)]\n",
    "#         self.biases = [b - (eta / len(mini_batch)) * nb\n",
    "#                        for b, nb in zip(self.biases, nabla_b)]\n",
    "\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        self.weights = [(1-eta*(lmbda/n))*w-(eta/len(mini_batch))*nw\n",
    "                        for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b-(eta/len(mini_batch))*nb\n",
    "                       for b, nb in zip(self.biases, nabla_b)]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        activation = x\n",
    "        activations = [x]\n",
    "        zs = []\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation) + b\n",
    "            zs.append(z)\n",
    "            activation = self.activate_func(z)\n",
    "            activations.append(activation)\n",
    "        delta = self.cost_derivative(activations[-1], y) * \\\n",
    "            self.activate_func_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = self.activate_func_prime(z)\n",
    "            delta = np.dot(self.weights[-l + 1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l - 1].transpose())\n",
    "        return (nabla_b, nabla_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=pd.read_excel('training_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['buffer', 'RTT', 'avg_speed', 'buffer_delay', 'stuck_ratio'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buffer</th>\n",
       "      <th>RTT</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>buffer_delay</th>\n",
       "      <th>stuck_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>74136.000000</td>\n",
       "      <td>74136.000000</td>\n",
       "      <td>74136.00000</td>\n",
       "      <td>74136.000000</td>\n",
       "      <td>74136.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40644.076751</td>\n",
       "      <td>51.597119</td>\n",
       "      <td>5739.62902</td>\n",
       "      <td>1440.801932</td>\n",
       "      <td>0.056414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22525.913360</td>\n",
       "      <td>21.781843</td>\n",
       "      <td>968.04202</td>\n",
       "      <td>1383.820098</td>\n",
       "      <td>0.790739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>304.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22718.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>5644.00000</td>\n",
       "      <td>855.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37189.500000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>5918.00000</td>\n",
       "      <td>1094.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55428.250000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>6147.00000</td>\n",
       "      <td>1557.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>159225.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>29332.00000</td>\n",
       "      <td>30552.000000</td>\n",
       "      <td>44.667000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              buffer           RTT    avg_speed  buffer_delay   stuck_ratio\n",
       "count   74136.000000  74136.000000  74136.00000  74136.000000  74136.000000\n",
       "mean    40644.076751     51.597119   5739.62902   1440.801932      0.056414\n",
       "std     22525.913360     21.781843    968.04202   1383.820098      0.790739\n",
       "min       304.000000     15.000000     10.00000    510.000000      0.000000\n",
       "25%     22718.000000     36.000000   5644.00000    855.000000      0.000000\n",
       "50%     37189.500000     47.000000   5918.00000   1094.000000      0.000000\n",
       "75%     55428.250000     61.000000   6147.00000   1557.000000      0.000000\n",
       "max    159225.000000    149.000000  29332.00000  30552.000000     44.667000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buffer</th>\n",
       "      <th>RTT</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>buffer_delay</th>\n",
       "      <th>stuck_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>buffer</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.199061</td>\n",
       "      <td>0.244814</td>\n",
       "      <td>-0.456585</td>\n",
       "      <td>-0.107332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RTT</th>\n",
       "      <td>-0.199061</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.053021</td>\n",
       "      <td>0.383575</td>\n",
       "      <td>0.043119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_speed</th>\n",
       "      <td>0.244814</td>\n",
       "      <td>-0.053021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.490241</td>\n",
       "      <td>-0.331971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buffer_delay</th>\n",
       "      <td>-0.456585</td>\n",
       "      <td>0.383575</td>\n",
       "      <td>-0.490241</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.279724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stuck_ratio</th>\n",
       "      <td>-0.107332</td>\n",
       "      <td>0.043119</td>\n",
       "      <td>-0.331971</td>\n",
       "      <td>0.279724</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                buffer       RTT  avg_speed  buffer_delay  stuck_ratio\n",
       "buffer        1.000000 -0.199061   0.244814     -0.456585    -0.107332\n",
       "RTT          -0.199061  1.000000  -0.053021      0.383575     0.043119\n",
       "avg_speed     0.244814 -0.053021   1.000000     -0.490241    -0.331971\n",
       "buffer_delay -0.456585  0.383575  -0.490241      1.000000     0.279724\n",
       "stuck_ratio  -0.107332  0.043119  -0.331971      0.279724     1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr() #可以看到各变量几乎相互独立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "\n",
    "def cost_derivative(a, y):\n",
    "    # return (output_activations-y)\n",
    "    return np.sum(np.nan_to_num(-y*np.log(a)-(1-y)*np.log(1-a)))\n",
    "\n",
    "def cost_func(a, y):\n",
    "    # return 0.5 * np.linalg.norm(output_activations - y)\n",
    "    return (a-y)\n",
    "\n",
    "func_model = {\"activate_func\": sigmoid,\n",
    "              \"activate_func_prime\": sigmoid_prime,\n",
    "              \"cost_func\": cost_func,\n",
    "              \"cost_derivative\": cost_derivative, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buffer</th>\n",
       "      <th>RTT</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>buffer_delay</th>\n",
       "      <th>stuck_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>10575</td>\n",
       "      <td>36</td>\n",
       "      <td>1643</td>\n",
       "      <td>4665</td>\n",
       "      <td>1.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>40323</td>\n",
       "      <td>73</td>\n",
       "      <td>5844</td>\n",
       "      <td>2817</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>22609</td>\n",
       "      <td>27</td>\n",
       "      <td>6792</td>\n",
       "      <td>5990</td>\n",
       "      <td>0.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>22648</td>\n",
       "      <td>94</td>\n",
       "      <td>3105</td>\n",
       "      <td>1879</td>\n",
       "      <td>0.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>7462</td>\n",
       "      <td>58</td>\n",
       "      <td>6262</td>\n",
       "      <td>3193</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     buffer  RTT  avg_speed  buffer_delay  stuck_ratio\n",
       "138   10575   36       1643          4665        1.355\n",
       "206   40323   73       5844          2817        0.025\n",
       "249   22609   27       6792          5990        0.170\n",
       "262   22648   94       3105          1879        0.299\n",
       "501    7462   58       6262          3193        0.029"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data=data[data['stuck_ratio']!=0]\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unify(series):\n",
    "    return (series-series.min())/(series.max()-series.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\84338\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "for i in training_data:\n",
    "    training_data[i]=unify(training_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buffer</th>\n",
       "      <th>RTT</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>buffer_delay</th>\n",
       "      <th>stuck_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.098041</td>\n",
       "      <td>0.145038</td>\n",
       "      <td>0.055692</td>\n",
       "      <td>0.135804</td>\n",
       "      <td>0.030314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.381999</td>\n",
       "      <td>0.427481</td>\n",
       "      <td>0.198963</td>\n",
       "      <td>0.074111</td>\n",
       "      <td>0.000537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.212911</td>\n",
       "      <td>0.076336</td>\n",
       "      <td>0.231294</td>\n",
       "      <td>0.180037</td>\n",
       "      <td>0.003784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0.213283</td>\n",
       "      <td>0.587786</td>\n",
       "      <td>0.105552</td>\n",
       "      <td>0.042798</td>\n",
       "      <td>0.006672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.068326</td>\n",
       "      <td>0.312977</td>\n",
       "      <td>0.213219</td>\n",
       "      <td>0.086663</td>\n",
       "      <td>0.000627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       buffer       RTT  avg_speed  buffer_delay  stuck_ratio\n",
       "138  0.098041  0.145038   0.055692      0.135804     0.030314\n",
       "206  0.381999  0.427481   0.198963      0.074111     0.000537\n",
       "249  0.212911  0.076336   0.231294      0.180037     0.003784\n",
       "262  0.213283  0.587786   0.105552      0.042798     0.006672\n",
       "501  0.068326  0.312977   0.213219      0.086663     0.000627"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs=np.vstack([training_data[\"buffer\"].values,training_data[\"RTT\"].values,training_data[\"avg_speed\"].values]).transpose()\n",
    "\n",
    "inputs=np.hsplit(inputs.transpose(),inputs[:,0].size)\n",
    "\n",
    "outputs=np.vstack([training_data[\"buffer_delay\"].values,training_data[\"stuck_ratio\"].values]).transpose()\n",
    "\n",
    "outputs=np.hsplit(outputs.transpose(),outputs[:,0].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.09804127],\n",
       "        [ 0.14503817],\n",
       "        [ 0.05569197]]), array([[ 0.13580371],\n",
       "        [ 0.03031389]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_train=list(zip(inputs,outputs))\n",
    "type(_train[0][1])\n",
    "_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4070"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network = Network([3,6,2], func_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2017, 5, 23, 14, 45, 32, 474841)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Cost: -0.0619715940601949\n",
      "Epoch 1 Cost: -0.06214272406268152\n",
      "Epoch 2 Cost: -0.06231031189456524\n",
      "Epoch 3 Cost: -0.062474460090722675\n",
      "Epoch 4 Cost: -0.06263526894675098\n",
      "Epoch 5 Cost: -0.06279283378658528\n",
      "Epoch 6 Cost: -0.06294724626062485\n",
      "Epoch 7 Cost: -0.06309859739004599\n",
      "Epoch 8 Cost: -0.06324697216631182\n",
      "Epoch 9 Cost: -0.06339245333933925\n",
      "Epoch 10 Cost: -0.06353512129520807\n",
      "Epoch 11 Cost: -0.06367505208701539\n",
      "Epoch 12 Cost: -0.06381232011096796\n",
      "Epoch 13 Cost: -0.06394699696472539\n",
      "Epoch 14 Cost: -0.06407915089072469\n",
      "Epoch 15 Cost: -0.06420884991207511\n",
      "Epoch 16 Cost: -0.06433615753423316\n",
      "Epoch 17 Cost: -0.06446113672715753\n",
      "Epoch 18 Cost: -0.06458384659153428\n",
      "Epoch 19 Cost: -0.06470434622044201\n",
      "Epoch 20 Cost: -0.06482269179356967\n",
      "Epoch 21 Cost: -0.06493893752697973\n",
      "Epoch 22 Cost: -0.06505313507579269\n",
      "Epoch 23 Cost: -0.06516533657753677\n",
      "Epoch 24 Cost: -0.06527559026686333\n",
      "Epoch 25 Cost: -0.06538394509458113\n",
      "Epoch 26 Cost: -0.06549044658401294\n",
      "Epoch 27 Cost: -0.06559513922306373\n",
      "Epoch 28 Cost: -0.0656980663784916\n",
      "Epoch 29 Cost: -0.0657992705989145\n",
      "Epoch 30 Cost: -0.06589879220602657\n",
      "Epoch 31 Cost: -0.06599667086336819\n",
      "Epoch 32 Cost: -0.06609294472577641\n",
      "Epoch 33 Cost: -0.06618765072682765\n",
      "Epoch 34 Cost: -0.06628082512594133\n",
      "Epoch 35 Cost: -0.06637250280854456\n",
      "Epoch 36 Cost: -0.06646271789223886\n",
      "Epoch 37 Cost: -0.06655150307230542\n",
      "Epoch 38 Cost: -0.06663889031035977\n",
      "Epoch 39 Cost: -0.06672491073416428\n",
      "Epoch 40 Cost: -0.0668095944978418\n",
      "Epoch 41 Cost: -0.06689297093590184\n",
      "Epoch 42 Cost: -0.06697506883879625\n",
      "Epoch 43 Cost: -0.06705591528483723\n",
      "Epoch 44 Cost: -0.0671355375149922\n",
      "Epoch 45 Cost: -0.06721396170540593\n",
      "Epoch 46 Cost: -0.06729121298831763\n",
      "Epoch 47 Cost: -0.06736731637794253\n",
      "Epoch 48 Cost: -0.06744229600380423\n",
      "Epoch 49 Cost: -0.06751617522822023\n",
      "Epoch 50 Cost: -0.06758897665570276\n",
      "Epoch 51 Cost: -0.06766072277375908\n",
      "Epoch 52 Cost: -0.06773143475296572\n",
      "Epoch 53 Cost: -0.06780113392753558\n",
      "Epoch 54 Cost: -0.06786984059918716\n",
      "Epoch 55 Cost: -0.06793757494842002\n",
      "Epoch 56 Cost: -0.0680043563654562\n",
      "Epoch 57 Cost: -0.06807020375320955\n",
      "Epoch 58 Cost: -0.06813513525905883\n",
      "Epoch 59 Cost: -0.06819916927367949\n",
      "Epoch 60 Cost: -0.06826232295861653\n",
      "Epoch 61 Cost: -0.06832461371374558\n",
      "Epoch 62 Cost: -0.06838605776999675\n",
      "Epoch 63 Cost: -0.06844667185768634\n",
      "Epoch 64 Cost: -0.06850647156893712\n",
      "Epoch 65 Cost: -0.06856547208315433\n",
      "Epoch 66 Cost: -0.0686236890006067\n",
      "Epoch 67 Cost: -0.06868113657306998\n",
      "Epoch 68 Cost: -0.06873782929078882\n",
      "Epoch 69 Cost: -0.06879378128425184\n",
      "Epoch 70 Cost: -0.06884900603653046\n",
      "Epoch 71 Cost: -0.06890351702811312\n",
      "Epoch 72 Cost: -0.0689573272026786\n",
      "Epoch 73 Cost: -0.0690104492563348\n",
      "Epoch 74 Cost: -0.0690628956849408\n",
      "Epoch 75 Cost: -0.06911467868707029\n",
      "Epoch 76 Cost: -0.06916580997518212\n",
      "Epoch 77 Cost: -0.06921630119324983\n",
      "Epoch 78 Cost: -0.06926616355937935\n",
      "Epoch 79 Cost: -0.06931540824107565\n",
      "Epoch 80 Cost: -0.06936404607915862\n",
      "Epoch 81 Cost: -0.06941208757581355\n",
      "Epoch 82 Cost: -0.0694595430880204\n",
      "Epoch 83 Cost: -0.06950642261637809\n",
      "Epoch 84 Cost: -0.06955273605718727\n",
      "Epoch 85 Cost: -0.06959849322365924\n",
      "Epoch 86 Cost: -0.06964370333421323\n",
      "Epoch 87 Cost: -0.06968837588223781\n",
      "Epoch 88 Cost: -0.06973251960120201\n",
      "Epoch 89 Cost: -0.06977614359332744\n",
      "Epoch 90 Cost: -0.06981925631122615\n",
      "Epoch 91 Cost: -0.06986186631108451\n",
      "Epoch 92 Cost: -0.06990398191375728\n",
      "Epoch 93 Cost: -0.069945611192908\n",
      "Epoch 94 Cost: -0.06998676198662328\n",
      "Epoch 95 Cost: -0.07002744217919384\n",
      "Epoch 96 Cost: -0.07006765930075036\n",
      "Epoch 97 Cost: -0.07010742091206987\n",
      "Epoch 98 Cost: -0.07014673428292045\n",
      "Epoch 99 Cost: -0.07018560642245023\n",
      "Epoch 100 Cost: -0.07022404451479905\n",
      "Epoch 101 Cost: -0.07026205526724305\n",
      "Epoch 102 Cost: -0.0702996453738884\n",
      "Epoch 103 Cost: -0.07033682158156986\n",
      "Epoch 104 Cost: -0.07037359018055216\n",
      "Epoch 105 Cost: -0.07040995757502863\n",
      "Epoch 106 Cost: -0.07044592987162589\n",
      "Epoch 107 Cost: -0.07048151316957699\n",
      "Epoch 108 Cost: -0.07051671339774934\n",
      "Epoch 109 Cost: -0.07055153649737982\n",
      "Epoch 110 Cost: -0.07058598810874331\n",
      "Epoch 111 Cost: -0.07062007377282685\n",
      "Epoch 112 Cost: -0.07065379907948806\n",
      "Epoch 113 Cost: -0.07068716942220485\n",
      "Epoch 114 Cost: -0.0707201900576238\n",
      "Epoch 115 Cost: -0.07075286609820292\n",
      "Epoch 116 Cost: -0.0707852027465491\n",
      "Epoch 117 Cost: -0.07081720485386618\n",
      "Epoch 118 Cost: -0.07084887744129058\n",
      "Epoch 119 Cost: -0.07088022522453777\n",
      "Epoch 120 Cost: -0.07091125298306544\n",
      "Epoch 121 Cost: -0.07094196529708133\n",
      "Epoch 122 Cost: -0.07097236672880743\n",
      "Epoch 123 Cost: -0.07100246169553524\n",
      "Epoch 124 Cost: -0.0710322546066481\n",
      "Epoch 125 Cost: -0.07106174970655448\n",
      "Epoch 126 Cost: -0.0710909512062224\n",
      "Epoch 127 Cost: -0.07111986335030417\n",
      "Epoch 128 Cost: -0.07114849001781104\n",
      "Epoch 129 Cost: -0.07117683538898635\n",
      "Epoch 130 Cost: -0.07120490324675952\n",
      "Epoch 131 Cost: -0.0712326974514524\n",
      "Epoch 132 Cost: -0.07126022178614465\n",
      "Epoch 133 Cost: -0.07128748003028677\n",
      "Epoch 134 Cost: -0.07131447576950022\n",
      "Epoch 135 Cost: -0.07134121252675509\n",
      "Epoch 136 Cost: -0.07136769392324223\n",
      "Epoch 137 Cost: -0.07139392337139382\n",
      "Epoch 138 Cost: -0.07141990425586418\n",
      "Epoch 139 Cost: -0.07144563989208057\n",
      "Epoch 140 Cost: -0.07147113361153629\n",
      "Epoch 141 Cost: -0.07149638855351925\n",
      "Epoch 142 Cost: -0.0715214079260313\n",
      "Epoch 143 Cost: -0.07154619488104903\n",
      "Epoch 144 Cost: -0.071570752443783\n",
      "Epoch 145 Cost: -0.07159508360384595\n",
      "Epoch 146 Cost: -0.07161919132650511\n",
      "Epoch 147 Cost: -0.07164307853580261\n",
      "Epoch 148 Cost: -0.07166674805047735\n",
      "Epoch 149 Cost: -0.07169020272321001\n",
      "time_consume: 0:01:02.012974\n"
     ]
    }
   ],
   "source": [
    "_start =datetime.datetime.now()\n",
    "network.SGD(_train[:3000],150,100,0.01,test_data=_train[3000:])\n",
    "_end=datetime.datetime.now()\n",
    "print(\"time_consume: {}\".format(_end-_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

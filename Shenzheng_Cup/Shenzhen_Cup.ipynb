{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "\n",
    "    def __init__(self, sizes, func_model):\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        self.activate_func = func_model[\"activate_func\"]\n",
    "        self.activate_func_prime = func_model[\"activate_func_prime\"]\n",
    "        self.cost_func = func_model[\"cost_func\"]\n",
    "        self.cost_derivative = func_model[\"cost_derivative\"]\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = self.activate_func(np.dot(w, a) + b)\n",
    "        return a\n",
    "\n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta, \n",
    "            test_data=None,\n",
    "            plot=False,\n",
    "            lmbda=0.0):\n",
    "        training_data = list(training_data)\n",
    "        n = len(training_data)\n",
    "        epoch_eval=[]\n",
    "        \n",
    "        if test_data:\n",
    "            test_data = list(test_data)\n",
    "            n_test = len(test_data)\n",
    "        \n",
    "        for j in range(epochs):\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [\n",
    "                training_data[k:k + mini_batch_size]\n",
    "                for k in range(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta, lmbda, len(training_data))\n",
    "            if test_data:\n",
    "                error=self.evaluate(test_data)\n",
    "\n",
    "                if plot:\n",
    "                    epoch_eval.append(error)\n",
    "                print(\"Epoch {} Cost: {}\".format(\n",
    "                    j, error))\n",
    "            else:\n",
    "                print(\"Epoch {} complete\".format(j))\n",
    "        if plot:\n",
    "            plt.plot(epoch_eval)\n",
    "            plt.show()\n",
    "\n",
    "    def evaluate(self,test_data):\n",
    "        def std(a,y):\n",
    "            return np.sqrt((a-y)**2)\n",
    "        return np.array([std(self.feedforward(item[0]),item[1]) for item in test_data]).mean()\n",
    "\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta, lmbda, n):\n",
    "\n",
    "#         nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "#         nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "#         for x, y in mini_batch:\n",
    "#             delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "#             nabla_b = [nb + dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "#             nabla_w = [nw + dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "#         self.weights = [w - (eta / len(mini_batch)) * nw\n",
    "#                         for w, nw in zip(self.weights, nabla_w)]\n",
    "#         self.biases = [b - (eta / len(mini_batch)) * nb\n",
    "#                        for b, nb in zip(self.biases, nabla_b)]\n",
    "\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        self.weights = [(1-eta*(lmbda/n))*w-(eta/len(mini_batch))*nw\n",
    "                        for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b-(eta/len(mini_batch))*nb\n",
    "                       for b, nb in zip(self.biases, nabla_b)]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        activation = x\n",
    "        activations = [x]\n",
    "        zs = []\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation) + b\n",
    "            zs.append(z)\n",
    "            activation = self.activate_func(z)\n",
    "            activations.append(activation)\n",
    "        delta = self.cost_derivative(activations[-1], y) * \\\n",
    "            self.activate_func_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = self.activate_func_prime(z)\n",
    "            delta = np.dot(self.weights[-l + 1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l - 1].transpose())\n",
    "        return (nabla_b, nabla_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=pd.read_excel('training_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['buffer', 'RTT', 'avg_speed', 'buffer_delay', 'stuck_ratio'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buffer</th>\n",
       "      <th>RTT</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>buffer_delay</th>\n",
       "      <th>stuck_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>74136.000000</td>\n",
       "      <td>74136.000000</td>\n",
       "      <td>74136.00000</td>\n",
       "      <td>74136.000000</td>\n",
       "      <td>74136.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40644.076751</td>\n",
       "      <td>51.597119</td>\n",
       "      <td>5739.62902</td>\n",
       "      <td>1440.801932</td>\n",
       "      <td>0.056414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22525.913360</td>\n",
       "      <td>21.781843</td>\n",
       "      <td>968.04202</td>\n",
       "      <td>1383.820098</td>\n",
       "      <td>0.790739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>304.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22718.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>5644.00000</td>\n",
       "      <td>855.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37189.500000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>5918.00000</td>\n",
       "      <td>1094.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55428.250000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>6147.00000</td>\n",
       "      <td>1557.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>159225.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>29332.00000</td>\n",
       "      <td>30552.000000</td>\n",
       "      <td>44.667000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              buffer           RTT    avg_speed  buffer_delay   stuck_ratio\n",
       "count   74136.000000  74136.000000  74136.00000  74136.000000  74136.000000\n",
       "mean    40644.076751     51.597119   5739.62902   1440.801932      0.056414\n",
       "std     22525.913360     21.781843    968.04202   1383.820098      0.790739\n",
       "min       304.000000     15.000000     10.00000    510.000000      0.000000\n",
       "25%     22718.000000     36.000000   5644.00000    855.000000      0.000000\n",
       "50%     37189.500000     47.000000   5918.00000   1094.000000      0.000000\n",
       "75%     55428.250000     61.000000   6147.00000   1557.000000      0.000000\n",
       "max    159225.000000    149.000000  29332.00000  30552.000000     44.667000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buffer</th>\n",
       "      <th>RTT</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>buffer_delay</th>\n",
       "      <th>stuck_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>buffer</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.199061</td>\n",
       "      <td>0.244814</td>\n",
       "      <td>-0.456585</td>\n",
       "      <td>-0.107332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RTT</th>\n",
       "      <td>-0.199061</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.053021</td>\n",
       "      <td>0.383575</td>\n",
       "      <td>0.043119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_speed</th>\n",
       "      <td>0.244814</td>\n",
       "      <td>-0.053021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.490241</td>\n",
       "      <td>-0.331971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buffer_delay</th>\n",
       "      <td>-0.456585</td>\n",
       "      <td>0.383575</td>\n",
       "      <td>-0.490241</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.279724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stuck_ratio</th>\n",
       "      <td>-0.107332</td>\n",
       "      <td>0.043119</td>\n",
       "      <td>-0.331971</td>\n",
       "      <td>0.279724</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                buffer       RTT  avg_speed  buffer_delay  stuck_ratio\n",
       "buffer        1.000000 -0.199061   0.244814     -0.456585    -0.107332\n",
       "RTT          -0.199061  1.000000  -0.053021      0.383575     0.043119\n",
       "avg_speed     0.244814 -0.053021   1.000000     -0.490241    -0.331971\n",
       "buffer_delay -0.456585  0.383575  -0.490241      1.000000     0.279724\n",
       "stuck_ratio  -0.107332  0.043119  -0.331971      0.279724     1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr() #可以看到各变量几乎相互独立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "\n",
    "def cost_derivative(a, y):\n",
    "    # return (output_activations-y)\n",
    "    return np.sum(np.nan_to_num(-y*np.log(a)-(1-y)*np.log(1-a)))\n",
    "\n",
    "def cost_func(a, y):\n",
    "    # return 0.5 * np.linalg.norm(output_activations - y)\n",
    "    return (a-y)\n",
    "\n",
    "func_model = {\"activate_func\": sigmoid,\n",
    "              \"activate_func_prime\": sigmoid_prime,\n",
    "              \"cost_func\": cost_func,\n",
    "              \"cost_derivative\": cost_derivative, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buffer</th>\n",
       "      <th>RTT</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>buffer_delay</th>\n",
       "      <th>stuck_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>10575</td>\n",
       "      <td>36</td>\n",
       "      <td>1643</td>\n",
       "      <td>4665</td>\n",
       "      <td>1.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>40323</td>\n",
       "      <td>73</td>\n",
       "      <td>5844</td>\n",
       "      <td>2817</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>22609</td>\n",
       "      <td>27</td>\n",
       "      <td>6792</td>\n",
       "      <td>5990</td>\n",
       "      <td>0.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>22648</td>\n",
       "      <td>94</td>\n",
       "      <td>3105</td>\n",
       "      <td>1879</td>\n",
       "      <td>0.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>7462</td>\n",
       "      <td>58</td>\n",
       "      <td>6262</td>\n",
       "      <td>3193</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     buffer  RTT  avg_speed  buffer_delay  stuck_ratio\n",
       "138   10575   36       1643          4665        1.355\n",
       "206   40323   73       5844          2817        0.025\n",
       "249   22609   27       6792          5990        0.170\n",
       "262   22648   94       3105          1879        0.299\n",
       "501    7462   58       6262          3193        0.029"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data=data[data['stuck_ratio']!=0]\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unify(series):\n",
    "    return (series-series.min())/(series.max()-series.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\84338\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "for i in training_data:\n",
    "    training_data[i]=unify(training_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buffer</th>\n",
       "      <th>RTT</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>buffer_delay</th>\n",
       "      <th>stuck_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.098041</td>\n",
       "      <td>0.145038</td>\n",
       "      <td>0.055692</td>\n",
       "      <td>0.135804</td>\n",
       "      <td>0.030314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.381999</td>\n",
       "      <td>0.427481</td>\n",
       "      <td>0.198963</td>\n",
       "      <td>0.074111</td>\n",
       "      <td>0.000537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.212911</td>\n",
       "      <td>0.076336</td>\n",
       "      <td>0.231294</td>\n",
       "      <td>0.180037</td>\n",
       "      <td>0.003784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0.213283</td>\n",
       "      <td>0.587786</td>\n",
       "      <td>0.105552</td>\n",
       "      <td>0.042798</td>\n",
       "      <td>0.006672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.068326</td>\n",
       "      <td>0.312977</td>\n",
       "      <td>0.213219</td>\n",
       "      <td>0.086663</td>\n",
       "      <td>0.000627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       buffer       RTT  avg_speed  buffer_delay  stuck_ratio\n",
       "138  0.098041  0.145038   0.055692      0.135804     0.030314\n",
       "206  0.381999  0.427481   0.198963      0.074111     0.000537\n",
       "249  0.212911  0.076336   0.231294      0.180037     0.003784\n",
       "262  0.213283  0.587786   0.105552      0.042798     0.006672\n",
       "501  0.068326  0.312977   0.213219      0.086663     0.000627"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs=np.vstack([training_data[\"buffer\"].values,training_data[\"RTT\"].values,training_data[\"avg_speed\"].values]).transpose()\n",
    "\n",
    "inputs=np.hsplit(inputs.transpose(),inputs[:,0].size)\n",
    "\n",
    "outputs=np.vstack([training_data[\"buffer_delay\"].values,training_data[\"stuck_ratio\"].values]).transpose()\n",
    "\n",
    "outputs=np.hsplit(outputs.transpose(),outputs[:,0].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.09804127],\n",
       "        [ 0.14503817],\n",
       "        [ 0.05569197]]), array([[ 0.13580371],\n",
       "        [ 0.03031389]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_train=list(zip(inputs,outputs))\n",
    "type(_train[0][1])\n",
    "_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4070"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network = Network([3,6,2], func_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2017, 5, 23, 14, 45, 32, 474841)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Cost: 0.32527661448445644\n",
      "Epoch 1 Cost: 0.2875179689746371\n",
      "Epoch 2 Cost: 0.25531675595981496\n",
      "Epoch 3 Cost: 0.22800375586751473\n",
      "Epoch 4 Cost: 0.20496401596893934\n",
      "Epoch 5 Cost: 0.1856285751525224\n",
      "Epoch 6 Cost: 0.16935589150338523\n",
      "Epoch 7 Cost: 0.15554452193101123\n",
      "Epoch 8 Cost: 0.14381185472969404\n",
      "Epoch 9 Cost: 0.13385451802182352\n",
      "Epoch 10 Cost: 0.12525310983492988\n",
      "Epoch 11 Cost: 0.11790975044582394\n",
      "Epoch 12 Cost: 0.11155838076189745\n",
      "Epoch 13 Cost: 0.10599692066266285\n",
      "Epoch 14 Cost: 0.1010773238453616\n",
      "Epoch 15 Cost: 0.09678110538230056\n",
      "Epoch 16 Cost: 0.09301854189278454\n",
      "Epoch 17 Cost: 0.08973203486647471\n",
      "Epoch 18 Cost: 0.08686512546060841\n",
      "Epoch 19 Cost: 0.08433951784820425\n",
      "Epoch 20 Cost: 0.08208544306876016\n",
      "Epoch 21 Cost: 0.08010745232620149\n",
      "Epoch 22 Cost: 0.07835531594443278\n",
      "Epoch 23 Cost: 0.0768013953085125\n",
      "Epoch 24 Cost: 0.07543425094605566\n",
      "Epoch 25 Cost: 0.0742490566458289\n",
      "Epoch 26 Cost: 0.07317156012293549\n",
      "Epoch 27 Cost: 0.07220933095454433\n",
      "Epoch 28 Cost: 0.07136357545567809\n",
      "Epoch 29 Cost: 0.07062045804885177\n",
      "Epoch 30 Cost: 0.06997006010907876\n",
      "Epoch 31 Cost: 0.06942417769164033\n",
      "Epoch 32 Cost: 0.06895111558710315\n",
      "Epoch 33 Cost: 0.06853723186896647\n",
      "Epoch 34 Cost: 0.06816333110747633\n",
      "Epoch 35 Cost: 0.06782228568892845\n",
      "Epoch 36 Cost: 0.06751827017667189\n",
      "Epoch 37 Cost: 0.06725173896354944\n",
      "Epoch 38 Cost: 0.06701641532153621\n",
      "Epoch 39 Cost: 0.06681113546321711\n",
      "Epoch 40 Cost: 0.06663437861256821\n",
      "Epoch 41 Cost: 0.06647925607123802\n",
      "Epoch 42 Cost: 0.0663460453292047\n",
      "Epoch 43 Cost: 0.06623052215447207\n",
      "Epoch 44 Cost: 0.06613254605066583\n",
      "Epoch 45 Cost: 0.06605507245829349\n",
      "Epoch 46 Cost: 0.06598986581070987\n",
      "Epoch 47 Cost: 0.06593318068582976\n",
      "Epoch 48 Cost: 0.06588847322505824\n",
      "Epoch 49 Cost: 0.06585634266291977\n",
      "Epoch 50 Cost: 0.06583390052690187\n",
      "Epoch 51 Cost: 0.06581605564878978\n",
      "Epoch 52 Cost: 0.06580206645085485\n",
      "Epoch 53 Cost: 0.06579390573303703\n",
      "Epoch 54 Cost: 0.06578987806971077\n",
      "Epoch 55 Cost: 0.06579344469025322\n",
      "Epoch 56 Cost: 0.06580441734500087\n",
      "Epoch 57 Cost: 0.06582185997193256\n",
      "Epoch 58 Cost: 0.0658414650658451\n",
      "Epoch 59 Cost: 0.06586361369608022\n",
      "Epoch 60 Cost: 0.06588777320972138\n",
      "Epoch 61 Cost: 0.06591443046185563\n",
      "Epoch 62 Cost: 0.06594271153956932\n",
      "Epoch 63 Cost: 0.06597145157436177\n",
      "Epoch 64 Cost: 0.06600479181066174\n",
      "Epoch 65 Cost: 0.06604119456150113\n",
      "Epoch 66 Cost: 0.06607897827810452\n",
      "Epoch 67 Cost: 0.06611870079184747\n",
      "Epoch 68 Cost: 0.06616149907032183\n",
      "Epoch 69 Cost: 0.06620691120863702\n",
      "Epoch 70 Cost: 0.0662533821864262\n",
      "Epoch 71 Cost: 0.06630042591245909\n",
      "Epoch 72 Cost: 0.06634799928973144\n",
      "Epoch 73 Cost: 0.0663972878834252\n",
      "Epoch 74 Cost: 0.06644747445181064\n",
      "Epoch 75 Cost: 0.06649903106421487\n",
      "Epoch 76 Cost: 0.0665495095407246\n",
      "Epoch 77 Cost: 0.06659959602046969\n",
      "Epoch 78 Cost: 0.06664952265988532\n",
      "Epoch 79 Cost: 0.06669985411526906\n",
      "Epoch 80 Cost: 0.06675042236379145\n",
      "Epoch 81 Cost: 0.06680082802460008\n",
      "Epoch 82 Cost: 0.0668504603516651\n",
      "Epoch 83 Cost: 0.06689925354557094\n",
      "Epoch 84 Cost: 0.06694721720270168\n",
      "Epoch 85 Cost: 0.06699463494337499\n",
      "Epoch 86 Cost: 0.06704312795140478\n",
      "Epoch 87 Cost: 0.06709242852086524\n",
      "Epoch 88 Cost: 0.06714097294119391\n",
      "Epoch 89 Cost: 0.06718909821483167\n",
      "Epoch 90 Cost: 0.06723665275931197\n",
      "Epoch 91 Cost: 0.06728394811036925\n",
      "Epoch 92 Cost: 0.0673310185197704\n",
      "Epoch 93 Cost: 0.06737863795105266\n",
      "Epoch 94 Cost: 0.06742649985458507\n",
      "Epoch 95 Cost: 0.06747433446081824\n",
      "Epoch 96 Cost: 0.06752186225855746\n",
      "Epoch 97 Cost: 0.06756883196306063\n",
      "Epoch 98 Cost: 0.06761574371787742\n",
      "Epoch 99 Cost: 0.06766282968679695\n",
      "Epoch 100 Cost: 0.0677099577497277\n",
      "Epoch 101 Cost: 0.06775751391809848\n",
      "Epoch 102 Cost: 0.06780510134235056\n",
      "Epoch 103 Cost: 0.06785267808375037\n",
      "Epoch 104 Cost: 0.06790046133098782\n",
      "Epoch 105 Cost: 0.06794812158610569\n",
      "Epoch 106 Cost: 0.06799554099688086\n",
      "Epoch 107 Cost: 0.0680426689511309\n",
      "Epoch 108 Cost: 0.06808934426945829\n",
      "Epoch 109 Cost: 0.06813608096825365\n",
      "Epoch 110 Cost: 0.06818297053936265\n",
      "Epoch 111 Cost: 0.06822996764997194\n",
      "Epoch 112 Cost: 0.06827728857431702\n",
      "Epoch 113 Cost: 0.06832419499601525\n",
      "Epoch 114 Cost: 0.06837127971655405\n",
      "Epoch 115 Cost: 0.06841841298217045\n",
      "Epoch 116 Cost: 0.06846515854948879\n",
      "Epoch 117 Cost: 0.06851141914519761\n",
      "Epoch 118 Cost: 0.06855698915628167\n",
      "Epoch 119 Cost: 0.0686022473840088\n",
      "Epoch 120 Cost: 0.06864715339387362\n",
      "Epoch 121 Cost: 0.06869142101850242\n",
      "Epoch 122 Cost: 0.06873579768965371\n",
      "Epoch 123 Cost: 0.06877998713052584\n",
      "Epoch 124 Cost: 0.06882370193160345\n",
      "Epoch 125 Cost: 0.06886681577114827\n",
      "Epoch 126 Cost: 0.06890956670814677\n",
      "Epoch 127 Cost: 0.0689522659246476\n",
      "Epoch 128 Cost: 0.06899455499082459\n",
      "Epoch 129 Cost: 0.06903663735877145\n",
      "Epoch 130 Cost: 0.06907843707133343\n",
      "Epoch 131 Cost: 0.06912016990279832\n",
      "Epoch 132 Cost: 0.06916176473158185\n",
      "Epoch 133 Cost: 0.06920315194996066\n",
      "Epoch 134 Cost: 0.06924429173201908\n",
      "Epoch 135 Cost: 0.06928476772352203\n",
      "Epoch 136 Cost: 0.06932495323232561\n",
      "Epoch 137 Cost: 0.06936490422932268\n",
      "Epoch 138 Cost: 0.06940433327258295\n",
      "Epoch 139 Cost: 0.06944324646617112\n",
      "Epoch 140 Cost: 0.06948191128801684\n",
      "Epoch 141 Cost: 0.06952020286075976\n",
      "Epoch 142 Cost: 0.06955816136853717\n",
      "Epoch 143 Cost: 0.06959607761054311\n",
      "Epoch 144 Cost: 0.06963343116871291\n",
      "Epoch 145 Cost: 0.0696704087411863\n",
      "Epoch 146 Cost: 0.06970700151276685\n",
      "Epoch 147 Cost: 0.06974322373984634\n",
      "Epoch 148 Cost: 0.06977902374366195\n",
      "Epoch 149 Cost: 0.06981457223840155\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGqpJREFUeJzt3XlwnPWd5/H3t1tn67YubPmQwSYgIIARkIMkw8IQQzJx\nNlM1MQVzwrDUhkqYyhwkqclWavafmc0cSQ2MlyVs2JkkZCuLN2xCOBNyDCSxHC4b8ImNLRtLlg/5\n0tHq7/7Rj0xLbkktW9LTep7Pq0rlfq7WR7b7459//TxPm7sjIiLxkQg7gIiIzC0Vv4hIzKj4RURi\nRsUvIhIzKn4RkZhR8YuIxIyKX0QkZlT8IiIxo+IXEYmZkrAD5NPU1OTt7e1hxxARmTc2btx40N2b\nC9m3KIu/vb2drq6usGOIiMwbZra70H011SMiEjMqfhGRmFHxi4jEjIpfRCRmVPwiIjGj4hcRiRkV\nv4hIzESm+N2drz+3jZ9u7Q07iohIUYtM8ZsZ/+NnO3l+S0/YUUREilpkih+gLlXK0ZPDYccQESlq\nkSr++lQpR06p+EVEJhOt4q8s48jJobBjiIgUtWgVv0b8IiJTil7xa45fRGRS0Sr+YKonk/Gwo4iI\nFK1oFX+qlIzD8aF02FFERIpWpIq/rrIUQKd0iohMIlLFX58qA9A8v4jIJCJV/A2p7Ij/yCmd0iki\nMpFIFX99UPyHNeIXEZlQpIq/rjI71XNUF3GJiEwoYsUfTPVoxC8iMqFIFX9ZSYKqsqSu3hURmUSk\nih+yZ/ZoxC8iMrGCit/MVpvZFjPbbmb35dm+xsxeNbOXzazLzK4r9NiZVp8q5ajO6hERmdCUxW9m\nSeB+4GagA7jVzDrG7fYccLm7XwH8CfDQNI6dUfWpUp3VIyIyiUJG/NcA2919p7sPAY8Ca3J3cPfj\n7j56g5wqwAs9dqbp1swiIpMrpPjbgD05y3uDdWOY2X80szeBH5Id9Rd8bHD8XcE0UVdv79l/bm5d\nqpSjenNXRGRCM/bmrruvd/eLgE8Cf3MWxz/o7p3u3tnc3HzWORqCWzO/+x8QERHJVUjxdwNLcpYX\nB+vycvefAeebWdN0j50J9ZVlpDPOiaGR2fw2IiLzViHFvwFYaWbLzawMWAs8nruDma0wMwserwLK\ngb5Cjp1pdaP369E8v4hIXiVT7eDuaTO7B3gKSAIPu/tmM7s72L4O+F3gD8xsGDgFfDp4szfvsbP0\nswBQn3P17uKG2fxOIiLz05TFD+DuTwBPjFu3Lufx3wJ/W+ixs0m3ZhYRmVzkrtzVrZlFRCYXueJ/\nd45fI34RkXyiV/yjH7+oc/lFRPKKXPGXlyRJlSU5fEJTPSIi+USu+AEaUmUc0umcIiJ5RbL4G6vL\nOKQRv4hIXpEs/gVVKn4RkYlEtvj7jqv4RUTyiWTxN1WX03diMOwYIiJFKZLFv6CqjIHhDCeH0mFH\nEREpOpEtfkDTPSIieUSy+Juqg+LXG7wiImeIZPEvqCoH4JDm+UVEzhDJ4m8MpnoOaqpHROQM0Sz+\nYKpH5/KLiJwpksWfKiuhojSh4hcRySOSxQ/QWFXOweOa4xcRGS+yxa/bNoiI5BfZ4teN2kRE8ots\n8et+PSIi+UW2+BurynS/HhGRPKJb/NXlul+PiEgekS1+3a9HRCS/yBb/6NW7ul+PiMhY0S3+at2v\nR0Qkn+gWv+7XIyKSV2SLf3SOX+fyi4iMFdniT5Uldb8eEZE8Ilv8Zpa9X88xzfGLiOQqqPjNbLWZ\nbTGz7WZ2X57tt5nZq2b2mpm9YGaX52zbFax/2cy6ZjL8VJpryunVjdpERMYomWoHM0sC9wO/DewF\nNpjZ4+7+es5ubwEfcffDZnYz8CBwbc7269394AzmLkhLTTm7+07O9bcVESlqhYz4rwG2u/tOdx8C\nHgXW5O7g7i+4++Fg8ZfA4pmNeXZaasvpOTYQdgwRkaJSSPG3AXtylvcG6yZyB/CjnGUHnjWzjWZ2\n1/Qjnr2WmgoOnxxmKJ2Zy28rIlLUppzqmQ4zu55s8V+Xs/o6d+82sxbgGTN7091/lufYu4C7AJYu\nXTojeVpqshdx9R4fpK2+ckaeU0RkvitkxN8NLMlZXhysG8PM3gs8BKxx977R9e7eHfzaA6wnO3V0\nBnd/0N073b2zubm58J9gEi212eI/0K/pHhGRUYUU/wZgpZktN7MyYC3weO4OZrYUeAz4fXffmrO+\nysxqRh8DNwGbZir8VFpqKgDo6deZPSIio6ac6nH3tJndAzwFJIGH3X2zmd0dbF8HfBloBB4wM4C0\nu3cCrcD6YF0J8G13f3JWfpI8Tk/16A1eEZHTCprjd/cngCfGrVuX8/hO4M48x+0ELh+/fq40VpeT\nMOjRRVwiIqdF9spdgGTCaKou11SPiEiOSBc/6Fx+EZHxol/8NRWa6hERyRGD4i/ngKZ6REROi0Xx\n950YJD2iq3dFRCAGxd9cW4G7PntXRGRU5It/9Fx+ndkjIpIVn+LXmT0iIkAMir+1Nrhtg87sEREB\nYlD8TdW6UZuISK7IF39ZSYIFVWUa8YuIBCJf/JCd5+/RiF9EBIhJ8S+qr2TfERW/iAjEpvgr2Hf0\nVNgxRESKQkyKv5IjJ4c5MZgOO4qISOhiUfyjn7e7X6N+EZF4FP/Cumzxa55fRCQmxb+oPnsR174j\nGvGLiMSi+FtrK0iYil9EBGJS/KXJBK21FXRrqkdEJB7FD6Pn8mvELyISm+JfWFehs3pERIhR8bfV\nV7Lv6ACZjIcdRUQkVLEp/kX1lQylM/okLhGJvVgVP+jMHhGR2BT/wrrsufya5xeRuItN8Y/etkGn\ndIpI3MWm+OtTpVSWJjXVIyKxF5viNzMW1VfQfVjFLyLxVlDxm9lqM9tiZtvN7L48228zs1fN7DUz\ne8HMLi/02Lm0uCHFnsMnw4wgIhK6KYvfzJLA/cDNQAdwq5l1jNvtLeAj7n4Z8DfAg9M4ds60N6Z4\nu+8k7jqXX0Tiq5AR/zXAdnff6e5DwKPAmtwd3P0Fdz8cLP4SWFzosXNpaWMVxwbTHNK5/CISY4UU\nfxuwJ2d5b7BuIncAPzrLY2dVe2MKgN2HNN0jIvE1o2/umtn1ZIv/r87i2LvMrMvMunp7e2cy1mnL\nRou/78SsPL+IyHxQSPF3A0tylhcH68Yws/cCDwFr3L1vOscCuPuD7t7p7p3Nzc2FZJ+2xQ0pzGB3\nn0b8IhJfhRT/BmClmS03szJgLfB47g5mthR4DPh9d986nWPnUkVpkkV1lSp+EYm1kql2cPe0md0D\nPAUkgYfdfbOZ3R1sXwd8GWgEHjAzgHQwes977Cz9LAVZuiClqR4RibUpix/A3Z8Anhi3bl3O4zuB\nOws9NkztTSme3nwg7BgiIqGJzZW7o5YuqKLvxBDHBobDjiIiEorYFf/pUzo1zy8iMRW74l+q4heR\nmItd8S9rrAJg9yG9wSsi8RS74q8uL6GpuozdBzXiF5F4il3xQ3bU/5ZO6RSRmIpl8a9ormZn7/Gw\nY4iIhCKWxb+ytZqDx4d0l04RiaVYFv+KlmoAth04FnISEZG5F8viX9laA8C2Hk33iEj8xLL4F9VV\nUFWWZLuKX0RiKJbFb2asaK1hW4+mekQkfmJZ/AArW6rZdkAjfhGJn1gXf8+xQY6e1M3aRCRe4lv8\nrcGZPZruEZGYiW/xt+jMHhGJp9gWf1t9JZWlSc3zi0jsxLb4EwljRUu1pnpEJHZiW/wA7zmvhjf2\n9+PuYUcREZkzsS7+SxbVcvD4ED3HBsOOIiIyZ2Jd/Je21QGwed/RkJOIiMydWBf/xQtrMYNN3f1h\nRxERmTOxLv7q8hKWN1ZpxC8isRLr4ge4pK1OI34RiZXYF/+li2rpPnKKw/pQFhGJidgX/yWLsm/w\nvr5fo34RiQcV/6JaADZ1a55fROIh9sXfUFVGW30lm/ZpxC8i8RD74ge4tK1WI34RiY2Cit/MVpvZ\nFjPbbmb35dl+kZm9aGaDZvbn47btMrPXzOxlM+uaqeAz6cqlDbx18AR9x3UFr4hE35TFb2ZJ4H7g\nZqADuNXMOsbtdgj4LPDVCZ7mene/wt07zyXsbOlc1gDAxt2HQ04iIjL7ChnxXwNsd/ed7j4EPAqs\nyd3B3XvcfQMwLz/O6tK2OsqSCTa+reIXkegrpPjbgD05y3uDdYVy4Fkz22hmd00n3FypKE1yaVst\nG3ep+EUk+ubizd3r3P0KslNFnzGzD+fbyczuMrMuM+vq7e2dg1hjXbWsgVe7jzKYHpnz7y0iMpcK\nKf5uYEnO8uJgXUHcvTv4tQdYT3bqKN9+D7p7p7t3Njc3F/r0M+aqZQ0MpTO6fYOIRF4hxb8BWGlm\ny82sDFgLPF7Ik5tZlZnVjD4GbgI2nW3Y2bQqeIP3N3qDV0QirmSqHdw9bWb3AE8BSeBhd99sZncH\n29eZ2XlAF1ALZMzsXrJnADUB681s9Ht9292fnJ0f5dy01FSwdEGKrt2H+FPODzuOiMismbL4Adz9\nCeCJcevW5Tx+h+wU0Hj9wOXnEnAudbY38NMtvWQyTiJhYccREZkVunI3xwcuaKLvxBBvvKN5fhGJ\nLhV/jutWNAHwi20HQ04iIjJ7VPw5zqurYGVLNb/YruIXkehS8Y9z3comfv3WIQaGdT6/iESTin+c\nD61sYjCdoUtX8YpIRKn4x7l2eSOlSePn2+f+6mERkbmg4h+nqryEK5c26A1eEYksFX8eH7mwmc37\n+nnn6EDYUUREZpyKP4+bOloBeOaNAyEnERGZeSr+PFa0VLO8qYpnXlfxi0j0qPjzMDNu6mjlxR0H\n6R+Yl58tIyIyIRX/BH67o5XhEef5LTq7R0SiRcU/gSuXNtBUXcbTm98JO4qIyIxS8U8gmTBuvLiV\n57f06ipeEYkUFf8kfufyRRwfTOtNXhGJFBX/JN53fiML6ypY/1LBnzQpIlL0VPyTSCaMT17Zxk+3\n9tJ7bDDsOCIiM0LFP4VPXdnGSMb5f6/sCzuKiMiMUPFPYWVrDZe11fHYS3vDjiIiMiNU/AX43VVt\nbOru57W9R8OOIiJyzlT8BfjUVYtJlSX5Xy/uCjuKiMg5U/EXoLailE+tauP7r+zj8ImhsOOIiJwT\nFX+B/uD97QylM3y3a0/YUUREzomKv0AXttbw/vMb+dcXd5MeyYQdR0TkrKn4p+GPP9hO95FT/PC1\n/WFHERE5ayr+abjx4lYubK3mn3+8nUzGw44jInJWVPzTkEgYn7l+Bdt6jvO07t8jIvOUin+aPnbZ\nQtobU/zzT7bhrlG/iMw/Kv5pKkkm+M+/tYJN3f08tVmjfhGZfwoqfjNbbWZbzGy7md2XZ/tFZvai\nmQ2a2Z9P59j56FOr2ljRUs3fPfkmwzrDR0TmmSmL38ySwP3AzUAHcKuZdYzb7RDwWeCrZ3HsvFOS\nTPBXqy9i58ETfHeDzusXkfmlkBH/NcB2d9/p7kPAo8Ca3B3cvcfdNwDjP5l8ymPnqxsvbuGa9gX8\n07NbOaYPZBeReaSQ4m8Dcoe1e4N1hTiXY4uamfGlj11M34kh/uGZrWHHEREpWNG8uWtmd5lZl5l1\n9fb2hh2nIJcvqef2a5fxyAu7eHXvkbDjiIgUpJDi7waW5CwvDtYVouBj3f1Bd+90987m5uYCnz58\nf7H6PTRWl/PF9a/pVg4iMi8UUvwbgJVmttzMyoC1wOMFPv+5HDsv1FaU8pVPXMKm7n7u/8mOsOOI\niEypZKod3D1tZvcATwFJ4GF332xmdwfb15nZeUAXUAtkzOxeoMPd+/MdO1s/TFhuuWwhn7xiEV//\n8TauW9nEVcsawo4kIjIhK8arTzs7O72rqyvsGNPSPzDMLV/7OWbww89+iNqK0rAjiUiMmNlGd+8s\nZN+ieXN3vqutKOVra69g/5EB7n30ZUZ0EzcRKVIq/hl01bIF/Jff6eDHb/bw1ae3hB1HRCSvKef4\nZXpuf98yXt9/jH95fgftjSk+ffXSsCOJiIyh4p9hZsZXPnEJ3UdO8YXHXqOmopRbLlsYdiwRkdM0\n1TMLykoSrLt9FauWNvC5R1/iGd27X0SKiIp/lqTKSvjGH11Nx6I67v63jXz/5UKveRMRmV0q/llU\nV1nKt+68lqvbG7j3uy/z0M936sNbRCR0Kv5ZVl1ewjf/+Bo+2nEe//WHb/DF9a8xlNatHUQkPCr+\nOVBRmuSB21bxmesv4Du/3sPv/fcX2XPoZNixRCSmVPxzJJEw/uKjF/HAbavY0XOcW77+c9a/tFdT\nPyIy51T8c+yWyxbyxOc+xIWtNfzZd1/hjke66D5yKuxYIhIjKv4QLFmQ4n//p/fz1x/v4MUdfdzw\n98/zj89s5eRQOuxoIhIDKv6QJBPGHdct59nPf4QbL27la89t48N/9zzf+MVbDAyPhB1PRCJMd+cs\nEht3H+Lvn97KCzv6qE+V8umrl3D7tctYsiAVdjQRmQemc3dOFX+R+dXOPr75wi6efv0AGXduuKiF\ntVcv5UMXNlFekgw7nogUqekUv+7VU2SuPb+Ra89vZN+RU3z7V2/znV+/zbNv9FBTUcJNHefx8csX\n8sELmigr0SydiJwdjfiL3FA6w7/vOMgPXtnP06+/w7GBNKmyJFe3L+CDKxr5wAVNdCysJZGwsKOK\nSIg01RNRg+kRfrHtID/d2su/bz/Ijt4TQPbq4IsX1tCxsJZLFtVx0cIaljVWUVepTwGTaHJ3RjJO\nOvgaGXHSmQwjGWc4ZzmdcdIjHqzPbh+zPDL6HO9uGz1uJOMMjzgjo8sjwXOPe950JhMcl5NpJPc5\nMmPWjz4+c5tTnyrlyXs/fFa/J5rqiajykiQ3XNzKDRe3AnCgf4AXdhzkpbeP8Pq+fr63cS+PvLj7\n9P4NqVKWNVbR3phiWWMVSxekaK2toLW2nJaaCmorSzDT/xSiIpNbKONKbUxJ5Smt04WZU2LpfMtB\noU1UahOVXzq3mHO+99jlscU46fOF+Al3JQmjJGmUJBIkE0Zp0kgmssslpx/nXy4vL3l334SRTBql\nCSMZLNel5mawphF/hGQyzq6+E2w9cJy3D51gV99JdvedYNfBk+w7eorxf9TlJQlaastpri6nPlVG\nXWXpmK/aylKqypJUlCWpLA2+ysb+WprM/oUtlqmm0ZHgiDuZDIwEy5nT65yMB+unGBWmc0Z6Mz0q\nHJ505Dd2FHj6+55eHlvIo7nDeiknjDNLLvh7kXc553G2NBNBMVrwHOOXxxdlYoLnzdlvinJ+N9vY\n5dLk2OdO5uQoSSRIGEU7WNKIP6YSCeP85mrOb64+Y9tgeoR9Rwbo6R/gwLFBevoH6Dk2yIH+AXqP\nDfLO0QG2vHOM/lPDHBuc/oVkZrz74kkkSI57cSWmeC/ayP9icoICH1PcQZn72PUj7qGV33gTlV7p\nuDI5XXI5v1+pspKx5ZR7fM7v7dQjTCOZTAQjyomLMX8hn1l6Ey0Xyz/6UjgVf0yUlyRZ3lTF8qaq\nKfdNj2Q4NpCmf2CYk0MjnBoeYSD49dTwCKeGRhgYHuHk0EjOqDYTjHTfXR7dNpzJwCSFPFVXJ8xI\nJrIXvWUfZ38dXZ9IGMmc9clE7mPOWDe6fmxR5hlR5hTsGcun/4t+ZuEmE1a0o0IRUPFLHiXJBA1V\nZTRUlYUdRURmgU4GFxGJGRW/iEjMqPhFRGJGxS8iEjMqfhGRmFHxi4jEjIpfRCRmVPwiIjFTlPfq\nMbNeYPeUO+bXBBycwTizQRnPXbHnA2WcKcpYmGXu3lzIjkVZ/OfCzLoKvVFRWJTx3BV7PlDGmaKM\nM09TPSIiMaPiFxGJmSgW/4NhByiAMp67Ys8HyjhTlHGGRW6OX0REJhfFEb+IiEwiMsVvZqvNbIuZ\nbTez+8LOA2BmS8zsJ2b2upltNrPPBesXmNkzZrYt+LWhCLImzewlM/tBMWY0s3oz+56ZvWlmb5jZ\n+4spo5n9WfBnvMnMvmNmFcWQz8weNrMeM9uUs27CXGb2heA1tMXMPhpSvv8W/Dm/ambrzaw+rHwT\nZczZ9nkzczNrCjPjdEWi+M0sCdwP3Ax0ALeaWUe4qQBIA5939w7gfcBnglz3Ac+5+0rguWA5bJ8D\n3shZLraMXwOedPeLgMvJZi2KjGbWBnwW6HT3S4EksLZI8n0TWD1uXd5cwd/NtcAlwTEPBK+tuc73\nDHCpu78X2Ap8IcR8E2XEzJYANwFv56wLK+O0RKL4gWuA7e6+092HgEeBNSFnwt33u/tvgsfHyJZV\nG9lsjwS7PQJ8MpyEWWa2GPgY8FDO6qLJaGZ1wIeBbwC4+5C7H6GIMpL9NLtKMysBUsA+iiCfu/8M\nODRu9US51gCPuvugu78FbCf72prTfO7+tLuPfvDzL4HFYeWbKGPgH4G/ZOynh4aScbqiUvxtwJ6c\n5b3BuqJhZu3AlcCvgFZ33x9segdoDSnWqH8i+xc4k7OumDIuB3qB/xlMRz1kZlUUSUZ37wa+Snbk\ntx846u5PF0u+PCbKVYyvoz8BfhQ8Lpp8ZrYG6Hb3V8ZtKpqMk4lK8Rc1M6sG/g9wr7v3527z7GlV\noZ1aZWYfB3rcfeNE+4SdkexoehXwL+5+JXCCcdMmYWYM5sjXkP0HahFQZWa35+5TBL+HeRVrLgAz\n+xLZ6dJvhZ0ll5mlgC8CXw47y9mKSvF3A0tylhcH60JnZqVkS/9b7v5YsPqAmS0Mti8EesLKB3wQ\n+ISZ7SI7RfYfzOzfKK6Me4G97v6rYPl7ZP8hKJaMNwJvuXuvuw8DjwEfKKJ8402Uq2heR2b2R8DH\ngdv83XPOiyXfBWT/kX8leN0sBn5jZudRPBknFZXi3wCsNLPlZlZG9s2Vx0POhJkZ2XnpN9z9H3I2\nPQ78YfD4D4Hvz3W2Ue7+BXdf7O7tZH/ffuzut1NcGd8B9pjZe4JVNwCvUzwZ3wbeZ2ap4M/8BrLv\n5xRLvvEmyvU4sNbMys1sObAS+PVchzOz1WSnHj/h7idzNhVFPnd/zd1b3L09eN3sBVYFf0+LIuOU\n3D0SX8AtZM8A2AF8Kew8QabryP43+lXg5eDrFqCR7NkU24BngQVhZw3y/hbwg+BxUWUErgC6gt/L\n/ws0FFNG4CvAm8Am4F+B8mLIB3yH7PsOw2QL6o7JcgFfCl5DW4CbQ8q3new8+ehrZl1Y+SbKOG77\nLqApzIzT/dKVuyIiMROVqR4RESmQil9EJGZU/CIiMaPiFxGJGRW/iEjMqPhFRGJGxS8iEjMqfhGR\nmPn/PjBtnUFrDIAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28efb72ca20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_consume: 0:01:04.598858\n"
     ]
    }
   ],
   "source": [
    "_start =datetime.datetime.now()\n",
    "network.SGD(_train[:3000],150,100,0.01,test_data=_train[3000:],lmbda=0.01,plot=True)\n",
    "_end=datetime.datetime.now()\n",
    "print(\"time_consume: {}\".format(_end-_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
